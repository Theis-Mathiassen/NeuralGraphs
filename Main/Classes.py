#Imports
import torch
from torch.nn import Linear
import torch.nn.functional as F
from torch_geometric.nn import GCNConv
from torch_geometric.nn import global_mean_pool
from sklearn import metrics #Used For ROC-AUC

# constants
MANUAL_SEED = 12345

# graph convolutional network obj
class GCN(torch.nn.Module):
    def __init__(self, hidden_channels, dropout_rate, learning_rate, in_features=7, outfeatures = 2):
        super(GCN, self).__init__()
        torch.manual_seed(MANUAL_SEED)
        self.dropout_rate = dropout_rate
        self.learning_rate = learning_rate
        
        # Input layer
        self.conv1 = GCNConv(in_features, hidden_channels)

        # Hidden layers
        self.conv2 = GCNConv(hidden_channels, hidden_channels)
        self.conv3 = GCNConv(hidden_channels, hidden_channels)
        self.conv4 = GCNConv(hidden_channels, hidden_channels)
        self.conv5 = GCNConv(hidden_channels, hidden_channels)

        # Output layer
        self.lin = Linear(hidden_channels, outfeatures)

    # Foward propagation
    def forward(self, x, edge_index, batch):
        # 1. Obtain node embeddings
        x = self.conv1(x, edge_index)
        x = x.relu()
        x = self.conv2(x, edge_index)
        x = x.relu()
        x = self.conv3(x, edge_index)
        x = x.relu()
        x = self.conv4(x, edge_index)
        x = x.relu()
        x = self.conv5(x, edge_index)

        # 2. Readout layer
        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]

        # 3. Apply a final classifier
        x = F.dropout(x, p=self.dropout_rate, training=self.training)
        x = self.lin(x)

        return x 

# model obj
class BaseModel():
    def __init__(self, model: GCN, loss, optim):
        self.model = model
        self.loss_function = loss
        self.optimizer = optim


# The data generated by training the model over 1 epoch
class TrainData():
    def __init__(self):
        self.train_losses = 0
        self.train_accuracies = 0
        self.train_labels = []
        self.train_scores = []
        self.train_probability_estimates = []
        
# The data generated by Testing the model once
class TestData():
    def __init__(self):
        self.test_losses = 0 
        self.test_accuracy = 0
        self.test_scores = []       #Model Guesses
        self.test_labels = []       #Truths
        self.test_probability_estimates = []

# Data covering different evaluation metrics based on input TestData
class EvaluationMetricsData():
    def __init__(self, TestData):
        self.accuracy = TestData.accuracy
        self.TP = 0
        self.TF = 0
        self.FP = 0
        self.FN = 0

        #Calculate True positive, true negative, false positive, false negative
        amountOfLabels = len(TestData.test_labels)

        for count in range(amountOfLabels): 
            if TestData.test_labels[count] == 1:       #If graph is true
                if TestData.test_labels[count] == TestData.test_scores[count]: 
                    self.TP += 1
                else:
                    self.FN += 1
            elif TestData.test_labels[count][count] == 0:     #If graph is false
                if TestData.test_labels[count] == TestData.test_scores[count]: 
                    self.TF += 1
                else:
                    self.FP += 1
                self.TP = 0
        self.TP = self.TP / amountOfLabels
        self.TF = self.TF / amountOfLabels
        self.FP = self.FP / amountOfLabels
        self.FN = self.FN / amountOfLabels

        self.TPR = self.TP / (self.TP+self.FN)  #Sensitivity, Recall, true positive rate
        self.FPR = 1-self.TPR                   #false positive rate
        self.PREC = self.TP / (self.TP + self.FP) #Precision
        self.f1 = 2 * self.PREC * self.TPR / (self.PREC + self.TPR)

        #AUC ROC and PR AUC
        self.auc = metrics.roc_auc_score(TestData.labels, TestData.probabilities)
                     
    

# All data from a given set of hyperparameters.
# Data passed to plotting functions
class AllData():
    def __init__(self):
        self.train_accuracies = []
        self.train_losses = []
        self.train_labels = []
        self.train_scores = []
        self.train_probability_estimates = []
        self.test_losses = []
        self.test_accuracies = []
        self.test_scores = []
        self.test_labels = []
        self.test_probability_estimates = []

    def insert_train_data (self, data: TrainData):
        self.train_accuracies.append(data.train_accuracies)
        self.train_losses.append(data.train_losses)
        self.train_labels.extend(data.train_labels)
        self.train_scores.extend(data.train_scores)
        self.train_probability_estimates.extend(data.train_probability_estimates)
        
    def insert_test_data (self, data: TestData):
        self.test_accuracies.append(data.test_accuracy)
        self.test_losses.append(data.test_losses)
        self.test_labels.extend(data.test_labels)
        self.test_scores.extend(data.test_scores)
        self.test_probability_estimates.extend(data.test_probability_estimates)
